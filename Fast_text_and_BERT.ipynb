{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_Kazan_Express.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8Vy6viw7mZEz"
      ],
      "toc_visible": true,
      "mount_file_id": "1q5cqTLTWprDYWJRPBmgVjHc_tLthB0ey",
      "authorship_tag": "ABX9TyMcYGRQ/98TPLSXMh442a0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c973531dd36e477fb4b5596c9ff5f628": {
          "model_module": "catboost-widget",
          "model_name": "CatboostWidgetModel",
          "model_module_version": "^1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "catboost-widget",
            "_model_module_version": "^1.0.0",
            "_model_name": "CatboostWidgetModel",
            "_view_count": null,
            "_view_module": "catboost-widget",
            "_view_module_version": "^1.0.0",
            "_view_name": "CatboostWidgetView",
            "data": {
              "catboost_info": {
                "path": "catboost_info",
                "name": "catboost_info",
                "content": {
                  "passed_iterations": 0,
                  "total_iterations": 50,
                  "data": {
                    "iterations": [],
                    "meta": {
                      "test_sets": [
                        "test"
                      ],
                      "test_metrics": [
                        {
                          "best_value": "Min",
                          "name": "MultiClass"
                        },
                        {
                          "best_value": "Max",
                          "name": "Accuracy"
                        }
                      ],
                      "learn_metrics": [
                        {
                          "best_value": "Min",
                          "name": "MultiClass"
                        },
                        {
                          "best_value": "Max",
                          "name": "Accuracy"
                        }
                      ],
                      "launch_mode": "Train",
                      "parameters": "",
                      "iteration_count": 50,
                      "learn_sets": [
                        "learn"
                      ],
                      "name": "experiment"
                    }
                  }
                }
              }
            },
            "layout": "IPY_MODEL_c7274d4f55c242efb6e284f7626baf22"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnatoliyFominV/Kazan_Express/blob/main/Fast_text_and_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kazan Express\n",
        "Соревнование по классификации товаров по их описанию"
      ],
      "metadata": {
        "id": "wwHAieRPmhNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory data analis"
      ],
      "metadata": {
        "id": "F_M3GEVRkHBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Импорт пакетов и данных"
      ],
      "metadata": {
        "id": "IJX2JA-eV6yc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E273iCrvJR_",
        "outputId": "f85a58f0-1706-4c14-f388-9dd94ca48b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting igraph\n",
            "  Downloading igraph-0.9.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.4 MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.9.11 texttable-1.6.4\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost;\n",
        "!pip install igraph;\n",
        "import igraph\n",
        "import catboost\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
        "from sklearn.metrics import accuracy_score\n",
        "output.enable_custom_widget_manager()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_name = 'train.parquet'\n",
        "df = pd.read_parquet(f'/content/drive/My Drive/Colab Notebooks/Data/{file_name}')\n",
        "\n",
        "file_name = \"categories_tree.csv\"\n",
        "category_tree = pd.read_csv(f'/content/drive/My Drive/Colab Notebooks/Data/{file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "orRL4gi6vSi1",
        "outputId": "dced7df6-0be8-4f07-b587-e99a9667f375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id         rating  feedback_quantity    category_id\n",
              "count  2.834520e+05  283452.000000       283452.00000  283452.000000\n",
              "mean   9.401805e+05       1.814641            4.34656   12244.567295\n",
              "std    4.191303e+05       2.309150           34.67245    2543.823093\n",
              "min    9.500000e+01       0.000000           -1.00000    2598.000000\n",
              "25%    6.063808e+05       0.000000            0.00000   12049.000000\n",
              "50%    9.963495e+05       0.000000            0.00000   12730.000000\n",
              "75%    1.298164e+06       4.871795            2.00000   13408.000000\n",
              "max    1.655762e+06       5.000000         6102.00000   14559.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ea145da-e255-4882-89a9-7695bea702ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rating</th>\n",
              "      <th>feedback_quantity</th>\n",
              "      <th>category_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.834520e+05</td>\n",
              "      <td>283452.000000</td>\n",
              "      <td>283452.00000</td>\n",
              "      <td>283452.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.401805e+05</td>\n",
              "      <td>1.814641</td>\n",
              "      <td>4.34656</td>\n",
              "      <td>12244.567295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.191303e+05</td>\n",
              "      <td>2.309150</td>\n",
              "      <td>34.67245</td>\n",
              "      <td>2543.823093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.500000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>2598.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.063808e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>12049.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.963495e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>12730.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.298164e+06</td>\n",
              "      <td>4.871795</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>13408.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.655762e+06</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6102.00000</td>\n",
              "      <td>14559.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ea145da-e255-4882-89a9-7695bea702ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ea145da-e255-4882-89a9-7695bea702ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ea145da-e255-4882-89a9-7695bea702ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lUSFMTUx8yif",
        "outputId": "ca725c48-3134-4ea4-f564-ff40800cedd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id                                              title  \\\n",
              "32163    681969                Очищающая пенка для умывания, 150мл   \n",
              "155647  1310527  Память USB 2.0/ Флеш-накопитель USB/ USB-Флешк...   \n",
              "72401    934300      Поднос ажурный с ручками пластиковый 29х40 см   \n",
              "63655   1469408  Ремень текстильный тактический нейлоновый тяну...   \n",
              "178384  1284230               Сумка мужская через плечо из экокожи   \n",
              "227197  1482631                      Системный разъем microUSB №63   \n",
              "270331   767466  Верхнее покрытие E.Co Nails Dalmatian Top Coat...   \n",
              "262433  1210873             Повязка для девочек / Бантик для волос   \n",
              "15488    590304  Карточки для фотосессии и записей малыша новор...   \n",
              "248069   744355                       Почтовые открытки новогодние   \n",
              "\n",
              "                                        short_description  \\\n",
              "32163               Очищающая пенка с матирующим эффектом   \n",
              "155647  USB накопитель Perfeo с колпачком, модель C09 ...   \n",
              "72401   Поднос ажурный с ручками пластиковый 29х40 см ...   \n",
              "63655                                                None   \n",
              "178384                                               None   \n",
              "227197                                               None   \n",
              "270331                                               None   \n",
              "262433                        Ручная работа Цена за 1 шт.   \n",
              "15488   Карточки для фотосессии и записей малыша новор...   \n",
              "248069                                               None   \n",
              "\n",
              "             name_value_characteristics  rating  feedback_quantity  \\\n",
              "32163                              None  5.0000                  6   \n",
              "155647  Объем памяти:8Gb|16Gb|32Gb|64Gb  0.0000                  0   \n",
              "72401                              None  0.0000                  0   \n",
              "63655                              None  0.0000                  0   \n",
              "178384                             None  0.0000                  0   \n",
              "227197                             None  0.0000                  0   \n",
              "270331                             None  0.0000                  0   \n",
              "262433                             None  5.0000                  2   \n",
              "15488                              None  0.0000                  0   \n",
              "248069                             None  4.9375                 16   \n",
              "\n",
              "        category_id  \n",
              "32163         13269  \n",
              "155647        13786  \n",
              "72401         13474  \n",
              "63655         12618  \n",
              "178384        12556  \n",
              "227197        13066  \n",
              "270331        13021  \n",
              "262433        13274  \n",
              "15488         12545  \n",
              "248069        13407  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9718c632-d06f-4fc3-b5fc-b3f9368cf7a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>short_description</th>\n",
              "      <th>name_value_characteristics</th>\n",
              "      <th>rating</th>\n",
              "      <th>feedback_quantity</th>\n",
              "      <th>category_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32163</th>\n",
              "      <td>681969</td>\n",
              "      <td>Очищающая пенка для умывания, 150мл</td>\n",
              "      <td>Очищающая пенка с матирующим эффектом</td>\n",
              "      <td>None</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>6</td>\n",
              "      <td>13269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155647</th>\n",
              "      <td>1310527</td>\n",
              "      <td>Память USB 2.0/ Флеш-накопитель USB/ USB-Флешк...</td>\n",
              "      <td>USB накопитель Perfeo с колпачком, модель C09 ...</td>\n",
              "      <td>Объем памяти:8Gb|16Gb|32Gb|64Gb</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>13786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72401</th>\n",
              "      <td>934300</td>\n",
              "      <td>Поднос ажурный с ручками пластиковый 29х40 см</td>\n",
              "      <td>Поднос ажурный с ручками пластиковый 29х40 см ...</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>13474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63655</th>\n",
              "      <td>1469408</td>\n",
              "      <td>Ремень текстильный тактический нейлоновый тяну...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>12618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178384</th>\n",
              "      <td>1284230</td>\n",
              "      <td>Сумка мужская через плечо из экокожи</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>12556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227197</th>\n",
              "      <td>1482631</td>\n",
              "      <td>Системный разъем microUSB №63</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>13066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270331</th>\n",
              "      <td>767466</td>\n",
              "      <td>Верхнее покрытие E.Co Nails Dalmatian Top Coat...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>13021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262433</th>\n",
              "      <td>1210873</td>\n",
              "      <td>Повязка для девочек / Бантик для волос</td>\n",
              "      <td>Ручная работа Цена за 1 шт.</td>\n",
              "      <td>None</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>2</td>\n",
              "      <td>13274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15488</th>\n",
              "      <td>590304</td>\n",
              "      <td>Карточки для фотосессии и записей малыша новор...</td>\n",
              "      <td>Карточки для фотосессии и записей малыша новор...</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>12545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248069</th>\n",
              "      <td>744355</td>\n",
              "      <td>Почтовые открытки новогодние</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>4.9375</td>\n",
              "      <td>16</td>\n",
              "      <td>13407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9718c632-d06f-4fc3-b5fc-b3f9368cf7a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9718c632-d06f-4fc3-b5fc-b3f9368cf7a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9718c632-d06f-4fc3-b5fc-b3f9368cf7a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhcRPYgN_frf",
        "outputId": "a59c6634-48d0-4619-c63e-38ed800f57c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 283452 entries, 0 to 283451\n",
            "Data columns (total 7 columns):\n",
            " #   Column                      Non-Null Count   Dtype  \n",
            "---  ------                      --------------   -----  \n",
            " 0   id                          283452 non-null  int64  \n",
            " 1   title                       283452 non-null  object \n",
            " 2   short_description           133130 non-null  object \n",
            " 3   name_value_characteristics  50360 non-null   object \n",
            " 4   rating                      283452 non-null  float64\n",
            " 5   feedback_quantity           283452 non-null  int64  \n",
            " 6   category_id                 283452 non-null  int64  \n",
            "dtypes: float64(1), int64(3), object(3)\n",
            "memory usage: 15.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.short_description.fillna(\"\", inplace=True);\n",
        "df.name_value_characteristics.fillna(\"\", inplace=True);"
      ],
      "metadata": {
        "id": "tYS_ysHsRXYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Устраняем дисбаланс классов"
      ],
      "metadata": {
        "id": "FZkNkHu-P5Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def take_n_samles(x):\n",
        "    n = 1000\n",
        "    n_object_in_class = g.size()[x.category_id].iloc[0]\n",
        "    \n",
        "    if n > n_object_in_class:\n",
        "        return x.sample(n_object_in_class).reset_index(drop=True)\n",
        "    elif n <= n_object_in_class:\n",
        "        return x.sample(n).reset_index(drop=True)\n",
        "\n",
        "df_class_balanced = df.copy()  # Скопируем дф\n",
        "g = df_class_balanced.groupby(\"category_id\")  # Сгруппируем по категориям\n",
        "df_balanced = g.apply(take_n_samles)  # Возьмём по 60 товаров в каждой категории, или меньше\n",
        "df_balanced = df_balanced.reset_index(drop=True)  # Удалим индексы (они дублируют столбец категорий) "
      ],
      "metadata": {
        "id": "jv4725bbQ2rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df_balanced, test_size=0.5, stratify=df_balanced.category_id)\n",
        "y_train = train[\"category_id\"]\n",
        "x_train = train.drop(columns=[\"id\",\"category_id\"])  # Удаляем id рейтинг и число отзывов они не влияют на категорию\n",
        "\n",
        "test = df.drop(train.index)\n",
        "y_test = test[\"category_id\"]\n",
        "x_test = test.drop(columns=[\"id\",\"category_id\"])"
      ],
      "metadata": {
        "id": "xeD5bvW6Q3KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Число классов в трейне\n",
        "category_in_train = len(train.groupby(\"category_id\")[\"id\"].count())\n",
        "category_in_test = len(test.groupby(\"category_id\")[\"id\"].count())\n",
        "print(f\"Число категорий в обучающей {category_in_train}, тестовой: {category_in_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy8ZHkSzuYhY",
        "outputId": "dccd1c54-bca8-487b-e50a-8ce3a22222fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число категорий в обучающей 1231, тестовой: 1215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fastex"
      ],
      "metadata": {
        "id": "viEbW7YwkPBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utils for F1 hierarhical"
      ],
      "metadata": {
        "id": "8Vy6viw7mZEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "from typing import Union, Tuple\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Iterable\n",
        "\n",
        "\n",
        "class CategoryTree(object):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.tree = dict()\n",
        "        self.proba_cache = dict()\n",
        "        self.curr_dir = Path(\".\").parent\n",
        "        return\n",
        "\n",
        "    def __getitem__(self, node_id: int) -> None:\n",
        "        return self.tree[node_id]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tree)\n",
        "\n",
        "    def keys(self) -> Iterable:\n",
        "        return self.tree.keys()\n",
        "\n",
        "    def items(self) -> Iterable:\n",
        "        return self.tree.items()\n",
        "\n",
        "    def save_tree(self, fname: str, directory: str = '') -> None:\n",
        "        path = os.path.join(self.curr_dir, directory, fname)\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self.tree, f)\n",
        "        return\n",
        "\n",
        "    def load_tree(self, fname: str, directory: str = '') -> None:\n",
        "        path = os.path.join(self.curr_dir, directory, fname)\n",
        "        with open(path, 'rb') as f:\n",
        "            self.tree = pickle.load(f)\n",
        "\n",
        "    def add_nodes_from_df(self, data: pd.DataFrame, parent_id_col: str, title_col: str) -> None:\n",
        "        for key, row in data.iterrows():\n",
        "            self.tree[key] = {'parent_id': row[parent_id_col],\n",
        "                              'children_ids': set(),\n",
        "                              'title': row[title_col],\n",
        "                              'ancestral_titles': set(),\n",
        "                              'embedding': np.array([]),\n",
        "                              'weights': np.array([]),\n",
        "                              'intercept': 0.,\n",
        "                              'good_count': 0,\n",
        "                              'good_ids': []\n",
        "                              }\n",
        "        self.update_ancestors()\n",
        "        return\n",
        "\n",
        "    def add_goods_from_df(self, data: pd.DataFrame, category_id_col: str, good_id_col: str) -> None:\n",
        "        for key, row in data.iterrows():\n",
        "            self.add_good(row[category_id_col], row[good_id_col])\n",
        "        return\n",
        "\n",
        "    def add_good(self, cat_id: int, good_id: int) -> None:\n",
        "        curr_id = cat_id\n",
        "        while True:\n",
        "            self.tree[curr_id]['good_ids'].append(good_id)\n",
        "            self.tree[curr_id]['good_count'] += 1\n",
        "            next_id = self[curr_id]['parent_id']\n",
        "            if next_id == 0:\n",
        "                break\n",
        "            self.tree[curr_id]['ancestral_titles'].add(self[next_id]['title'])\n",
        "            self.tree[curr_id]['ancestral_titles'].update(self[next_id]['ancestral_titles'])\n",
        "            self.tree[next_id]['children_ids'].add(curr_id)\n",
        "            curr_id = next_id\n",
        "        return\n",
        "\n",
        "    def update_ancestors(self) -> None:\n",
        "        for i in range(3):\n",
        "            for curr_id in self.keys():\n",
        "                next_id = self.tree[curr_id]['parent_id']\n",
        "                if next_id == 0 or next_id not in self.keys():\n",
        "                    continue\n",
        "                self.tree[curr_id]['ancestral_titles'].add(self[next_id]['title'])\n",
        "                self.tree[curr_id]['ancestral_titles'].update(self[next_id]['ancestral_titles'])\n",
        "        return\n",
        "\n",
        "    def update_embeddings(self, embeddings_dict: dict) -> None:\n",
        "        dim = embeddings_dict[next(iter(embeddings_dict))].shape[0]\n",
        "        for _, node in self.items():\n",
        "            if node['good_count'] > 0:\n",
        "                node['embedding'] = np.zeros((dim,), dtype='float32')\n",
        "                for good_id in node['good_ids']:\n",
        "                    node['embedding'] += embeddings_dict[good_id] / node['good_count']\n",
        "        for _, node in self.items():\n",
        "            node['embedding'] = node['embedding'] / (np.linalg.norm(node['embedding']) + 0.001)\n",
        "        return\n",
        "\n",
        "    def mix_in_description_embs(self, encoder: callable, weight: int = 4) -> None:\n",
        "        id_list = list(self.keys())\n",
        "        path_titles = []\n",
        "        for node_id in id_list:\n",
        "            path_title = [self[node_id]['title']] + list(self[node_id]['ancestral_titles']).copy()\n",
        "            if 'Все категории' in path_title:\n",
        "                path_title.remove('Все категории')\n",
        "            path_titles.append(' '.join(path_title))\n",
        "        title_embeddings = encoder(path_titles)\n",
        "        for node_id, embedding in zip(id_list, title_embeddings):\n",
        "            if self.tree[node_id]['embedding'].shape[0] == 0:\n",
        "                self.tree[node_id]['embedding'] = embedding\n",
        "            else:\n",
        "                self.tree[node_id]['embedding'] = (self.tree[node_id]['embedding'] * (\n",
        "                    self.tree[node_id]['good_count']) ** 0.5\n",
        "                                                   + embedding * weight) / (\n",
        "                                                          (self.tree[node_id]['good_count']) ** 0.5 + weight)\n",
        "        return\n",
        "\n",
        "    def get_siblings_ids(self, node_id: int) -> [set | None]:\n",
        "        if (node_id not in self.tree) or (self[node_id]['good_count'] == 0):\n",
        "            return None\n",
        "        parent = self[node_id]['parent_id']\n",
        "        if parent == 0:\n",
        "            return None\n",
        "        childs = self[parent]['children_ids'].copy()\n",
        "        if not childs:\n",
        "            return None\n",
        "        childs.remove(node_id)\n",
        "        return childs\n",
        "\n",
        "    def choose_leaf(self, classifier: callable, good_embedding: np.array = None, document: str = None) -> int:\n",
        "        current_id = 1\n",
        "        next_id = 1\n",
        "        while next_id:\n",
        "            current_id = next_id\n",
        "            next_id, _ = self.choose_child(current_id,\n",
        "                                           classifier=classifier,\n",
        "                                           good_embedding=good_embedding,\n",
        "                                           document=document)\n",
        "        self.proba_cache = dict()\n",
        "        return current_id\n",
        "\n",
        "    def choose_leaf_proba(self, classifier: callable,\n",
        "                          good_embedding: np.array = None,\n",
        "                          document: str = None) -> Tuple[int, float]:\n",
        "        next_id = 1\n",
        "        current_id = 1\n",
        "        leaf_proba = 1.\n",
        "        while next_id:\n",
        "            current_id = next_id\n",
        "            next_id, proba = self.choose_child(current_id,\n",
        "                                               classifier=classifier,\n",
        "                                               good_embedding=good_embedding,\n",
        "                                               document=document)\n",
        "            leaf_proba *= proba\n",
        "        self.proba_cache = dict()\n",
        "        return current_id, leaf_proba\n",
        "\n",
        "    def choose_leaf_proba_upwards(self, leaf_ids_probas: List[Tuple[int, float]],\n",
        "                                  classifier: callable,\n",
        "                                  good_embedding: np.array, proba_power: float = 1.,\n",
        "                                  sib_proba_power: float = 0.) -> Tuple[int, float]:\n",
        "        max_proba = 0.\n",
        "        best_leaf = 1\n",
        "        for leaf_id, leaf_proba in leaf_ids_probas:\n",
        "            next_node = self.tree[leaf_id]['parent_id']\n",
        "            proba = leaf_proba\n",
        "            while next_node > 1:\n",
        "                proba *= self.eval_node_proba(node_id=next_node,\n",
        "                                              classifier=classifier,\n",
        "                                              good_embedding=good_embedding) ** proba_power\n",
        "                siblings = self.get_siblings_ids(next_node)\n",
        "                sibl_proba = sib_proba_power\n",
        "                for sibling in siblings:\n",
        "                    sibl_proba += self.eval_node_proba(node_id=sibling,\n",
        "                                                       classifier=classifier,\n",
        "                                                       good_embedding=good_embedding)\n",
        "                proba /= (sibl_proba / (len(siblings) + 0.5) ** 0.3)\n",
        "                next_node = self.tree[next_node]['parent_id']\n",
        "            if proba > max_proba:\n",
        "                max_proba = proba\n",
        "                best_leaf = leaf_id\n",
        "        return best_leaf, max_proba\n",
        "\n",
        "    def choose_child(self, node_id: int, classifier: callable,\n",
        "                     good_embedding: np.array = None,\n",
        "                     document: str = None) -> Union[None, tuple]:\n",
        "\n",
        "        childs = self[node_id]['children_ids']\n",
        "        if len(childs) == 0:\n",
        "            return None, 1.\n",
        "        if len(childs) == 1:\n",
        "            return list(childs)[0], 1.0\n",
        "        max_proba = 0.\n",
        "        best_child = None\n",
        "        for child in childs:\n",
        "            proba = self.eval_node_full_proba(child,\n",
        "                                              classifier=classifier,\n",
        "                                              good_embedding=good_embedding,\n",
        "                                              document=document)\n",
        "            if max_proba < proba:\n",
        "                max_proba = proba\n",
        "                best_child = child\n",
        "        return best_child, max_proba\n",
        "\n",
        "    def eval_node_full_proba(self, node_id: int,\n",
        "                             good_embedding: np.array = None,\n",
        "                             document: str = None,\n",
        "                             classifier: callable = None) -> float:\n",
        "        \"\"\"Probability of node membership for certain commodity with considering child nodes probabilities\"\"\"\n",
        "        self_proba = self.eval_node_proba(node_id,\n",
        "                                          classifier=classifier,\n",
        "                                          good_embedding=good_embedding,\n",
        "                                          document=document)\n",
        "\n",
        "        childs = self[node_id]['children_ids']\n",
        "        if len(childs) == 0:\n",
        "            return self_proba\n",
        "        max_proba = 0.\n",
        "        sum_proba = 0.\n",
        "        for child in childs:\n",
        "            proba = self.eval_node_proba(child,\n",
        "                                         classifier=classifier,\n",
        "                                         good_embedding=good_embedding,\n",
        "                                         document=document)\n",
        "            sum_proba += proba ** 2\n",
        "            if max_proba < proba:\n",
        "                max_proba = proba\n",
        "        return (max_proba * 0.7 + sum_proba ** 0.5 * 0.3) * self_proba\n",
        "\n",
        "    def eval_node_proba(self, node_id: int,\n",
        "                        classifier: callable,\n",
        "                        good_embedding: np.array = None,\n",
        "                        document: str = None) -> float:\n",
        "        \"\"\"Probability of node membership for certain commodity without considering child nodes probabilities\"\"\"\n",
        "        if node_id in self.proba_cache:\n",
        "            return self.proba_cache[node_id]\n",
        "        elif document:\n",
        "            proba = classifier.predict_local_proba_by_doc(node_id, document)\n",
        "            print(proba)\n",
        "        elif len(self[node_id]['weights']) == 0:\n",
        "            return 1e-8\n",
        "        else:\n",
        "            proba = classifier.predict_local_proba(self[node_id]['weights'],\n",
        "                                                   self[node_id]['intercept'],\n",
        "                                                   self[node_id]['embedding'],\n",
        "                                                   good_embedding)\n",
        "        self.proba_cache[node_id] = proba\n",
        "        return proba\n",
        "\n",
        "    def get_id_path(self, node_id: int) -> list:\n",
        "        path = []\n",
        "        current_id = node_id\n",
        "        while current_id > 1:\n",
        "            path.append(current_id)\n",
        "            current_id = self[current_id]['parent_id']\n",
        "        return path\n",
        "\n",
        "    def get_id_path_set(self, node_id: int) -> set:\n",
        "        path = set()\n",
        "        current_id = node_id\n",
        "        while current_id > 1:\n",
        "            path.add(current_id)\n",
        "            current_id = self[current_id]['parent_id']\n",
        "        return path\n",
        "\n",
        "    def hF1_score(self, true_leafs: list, pred_leafs: list) -> Union[None, float]:\n",
        "        if len(true_leafs) != len(pred_leafs):\n",
        "            return None\n",
        "        sum_Ti = 0\n",
        "        sum_Pi = 0\n",
        "        sum_Ti_Pi = 0\n",
        "        for true, pred in zip(true_leafs, pred_leafs):\n",
        "            pr_rec_tuple = self.get_good_pr_rec(true, pred)\n",
        "            sum_Ti += pr_rec_tuple[0]\n",
        "            sum_Pi += pr_rec_tuple[1]\n",
        "            sum_Ti_Pi += pr_rec_tuple[2]\n",
        "\n",
        "        hP = sum_Ti_Pi / sum_Pi\n",
        "        hR = sum_Ti_Pi / sum_Ti\n",
        "        return 2 * hP * hR / (hP + hR)\n",
        "\n",
        "    def hF1_score_01(self, true_leafs, pred_leafs) -> Union[None, float]:\n",
        "        if len(true_leafs) != len(pred_leafs):\n",
        "            return None\n",
        "        sum_Ti = 0\n",
        "        sum_Pi = 0\n",
        "        sum_Ti_Pi = 0\n",
        "        for true, pred in zip(true_leafs, pred_leafs):\n",
        "            pr_rec_tuple = self.get_good_pr_rec(true, pred)\n",
        "            sum_Ti += pr_rec_tuple[0] + 2\n",
        "            sum_Pi += pr_rec_tuple[1] + 2\n",
        "            sum_Ti_Pi += pr_rec_tuple[2] + 2\n",
        "\n",
        "        hP = sum_Ti_Pi / sum_Pi\n",
        "        hR = sum_Ti_Pi / sum_Ti\n",
        "        return 2 * hP * hR / (hP + hR)\n",
        "\n",
        "    def get_good_pr_rec(self, good_category_id: int, predicted_leaf_id: int) -> tuple:\n",
        "        Ti_set = self.get_id_path_set(good_category_id)\n",
        "        Pi_set = self.get_id_path_set(predicted_leaf_id)\n",
        "        inter_set = Ti_set.intersection(Pi_set)\n",
        "        return len(Ti_set), len(Pi_set), len(inter_set)\n",
        "\n",
        "    def fit_local_weights(self, classifier: object, embeddings_dict: dict, C: int = 1,\n",
        "                          reg_count_power: float = 0.4, verbose=False) -> None:\n",
        "        \"\"\"Fitting of all local node classifiers, saving weights and intercept of logistic regression in tree\"\"\"\n",
        "        for key in tqdm.tqdm(list(self.keys()), total=len(self)):\n",
        "            siblings = self.get_siblings_ids(key)\n",
        "            if siblings:\n",
        "                siblings_goods = []\n",
        "                for sibling in siblings:\n",
        "                    siblings_goods += self[sibling]['good_ids']\n",
        "\n",
        "                dim = embeddings_dict[next(iter(embeddings_dict))].shape[0] + 1\n",
        "                if self.tree[key]['weights'].shape[0] == dim:\n",
        "                    warm_coefs = self.tree[key]['weights']\n",
        "                else:\n",
        "                    warm_coefs = np.zeros(dim)\n",
        "                self.tree[key]['weights'], \\\n",
        "                self.tree[key]['intercept'] = classifier.fit_node_weights(self[key]['good_ids'],\n",
        "                                                                          siblings_goods,\n",
        "                                                                          self[key]['embedding'],\n",
        "                                                                          embeddings_dict,\n",
        "                                                                          C_in=C,\n",
        "                                                                          reg_count_power=reg_count_power,\n",
        "                                                                          warm_coefs=warm_coefs,\n",
        "                                                                          warm_intercept=self.tree[key]['intercept'],\n",
        "                                                                          verbose=verbose)\n",
        "        return"
      ],
      "metadata": {
        "id": "jTNRUYeymeAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "PGDwcVXFXXVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext\n",
        "import os\n",
        "from pathlib import Path\n",
        "import fasttext\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import csv\n",
        "from gensim.utils import simple_preprocess\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_name = 'train.parquet'\n",
        "df = pd.read_parquet(f'/content/drive/My Drive/Colab Notebooks/Data/{file_name}')\n",
        "\n",
        "file_name = \"categories_tree.csv\"\n",
        "category_tree = pd.read_csv(f'/content/drive/My Drive/Colab Notebooks/Data/{file_name}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIYbZMuckiT5",
        "outputId": "e3f69a8f-3ce0-4ee0-9bae-7559f624e09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(value=\"\")"
      ],
      "metadata": {
        "id": "UvSUofQ3tzAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_full = df[['title', 'short_description', 'category_id']].copy()\n",
        "data_full[\"Document_new\"] = [name + \" \" + desc + \" __label__\" + str(label) for name, desc, label in zip(data_full[\"title\"],\tdata_full['short_description'],\tdata_full['category_id'])]\n",
        "data_full['Document_new'] = data_full['Document_new'].apply(simple_preprocess)\n",
        "data_full['Document_new'] = data_full['Document_new'].apply(lambda x: \" \".join(x[:50]))\n",
        "data_train = data_full.iloc[:int(249969 * 0.8)].copy()\n",
        "data_test = data_full.iloc[int(249969 * 0.8):].copy()"
      ],
      "metadata": {
        "id": "I3r2tJFEl4ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write to file for start Fastext\n",
        "with open(\"train_baseline.csv\",\"w\") as file:\n",
        "  for des, label in zip(data_train['Document_new'], data_train['category_id']):\n",
        "    print(f\"{des}\",end=\", \", file=file)\n",
        "    print(f\" __label__\" + str(label), file=file)\n",
        "\n",
        "with open(\"test_baseline.csv\",\"w\") as file:\n",
        "  for des, label in zip(data_test['Document_new'], data_test['category_id']):\n",
        "    print(f\"{des}\",end=\", \", file=file)\n",
        "    print(f\" __label__\" + str(label), file=file)"
      ],
      "metadata": {
        "id": "HvKLbtqFl4e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import exists \n",
        "\n",
        "file_name = \"fast_text_model_baseline.bin\"\n",
        "path_model = f'/content/drive/My Drive/Colab Notebooks/Data/{file_name}'\n",
        "\n",
        "if exists(path_model):\n",
        "  model = fasttext.load_model(path_model)\n",
        "\n",
        "else:\n",
        "  model = fasttext.train_supervised(input=\"train_baseline.csv\",\n",
        "                          lr = 0.3,\n",
        "                          dim=40,\n",
        "                          ws=5,\n",
        "                          wordNgrams=3,\n",
        "                          minCount=10)\n",
        "  model.save_model(path_model)"
      ],
      "metadata": {
        "id": "I-N8KpTHl4hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab19575f-4666-4e29-dc58-d497f3a7eb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(corpus):\n",
        "  ans = []\n",
        "  res = model.predict(corpus)\n",
        "  for text in res[0]:\n",
        "    ans.append(int(text[0][9:]))\n",
        "  return ans\n",
        "make_prediction([\"рифленный нож слайсер для фигурной нарезки см\",\"рифленный нож слайсер для фигурной нарезки см\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wj0hmt1mhyX",
        "outputId": "1243d253-4bb1-4c8f-8c8f-2573bd68309e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14030, 14030]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "tEr2GdQ3otiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi0bEdPeozDK",
        "outputId": "ba36f0e0-dbcf-4ea2-8744-0190f0bcf944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DataSet / Bert"
      ],
      "metadata": {
        "id": "Co24yzaaxyZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class KEDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=512, is_test=False, target_names=None):\n",
        "        # target_names - список наименований категорий в one-hot представлении целевой переменной. Формат элементов - str.\n",
        "        self.df = df\n",
        "        self.target_names = target_names\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        text  = row[\"text\"]\n",
        "        if not self.is_test: \n",
        "            label = row[self.target_names]\n",
        "            true_class = row['category_id']\n",
        "\n",
        "        tokenized_text = self.tokenizer(text, max_length=self.max_length, padding='max_length', truncation=True)\n",
        "\n",
        "        res = {\n",
        "            \"input_ids\": torch.Tensor(tokenized_text[\"input_ids\"]).long(),\n",
        "            \"token_type_ids\": torch.Tensor(tokenized_text[\"token_type_ids\"]).long(),\n",
        "            \"attention_mask\": torch.Tensor(tokenized_text[\"attention_mask\"]).long(),\n",
        "            }\n",
        "        if not self.is_test: res[\"label\"] = torch.Tensor(label).float()\n",
        "        if not self.is_test: res[\"true_class\"] = true_class\n",
        "        \n",
        "        return res\n",
        "    \n",
        "\n",
        "class BertClasifyByCLS(nn.Module):\n",
        "    def __init__(self, bert, emd_size=264, num_classes=2):\n",
        "        super(BertClasifyByCLS, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.num_classes = num_classes\n",
        "        self.drop_out = nn.Dropout(0.1)\n",
        "        self.clsf = nn.Linear(emd_size, self.num_classes)\n",
        "\n",
        "    def forward(self, input_ids_text,\n",
        "                      token_type,\n",
        "                      attention_mask_text):\n",
        "        bert_text_out = self.bert(input_ids_text,\n",
        "                                  token_type,\n",
        "                                  attention_mask_text)[0][:,0]\n",
        "        clsf_input = self.drop_out(bert_text_out)\n",
        "        return self.clsf(clsf_input)"
      ],
      "metadata": {
        "id": "xXdyJUnlxy26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Utils"
      ],
      "metadata": {
        "id": "RrF6DAOCyan_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import random, os\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def seed_everything(seed: int):   \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def get_path(G, pred):\n",
        "    #по предсказанной категории возвращает всю ветку до корня\n",
        "    # G - граф со структурой категорий\n",
        "    # pred - предсказанная категория, название категории в формате int\n",
        "    # возвращает всю ветку категорий от предсказанной категории до корня\n",
        "    node = pred\n",
        "    path = [node]\n",
        "    while list(G.predecessors(node)):\n",
        "        path.append(list(G.predecessors(node))[0])\n",
        "        node = list(G.predecessors(node))[0]\n",
        "    return set(path)\n",
        "\n",
        "def get_hF(G, y_true, y_pred):\n",
        "    # G - граф со структурой категорий\n",
        "    # y_true - истинные метки классов,  названия категории в формате int\n",
        "    # y_pred - предсказанные метки классов,  названия категории в формате int\n",
        "    # возвращает рассчитанное значение иерархического f1.\n",
        "    assert len(y_true) == len(y_pred)\n",
        "    P_T = 0\n",
        "    P = 0\n",
        "    T = 0\n",
        "    for i in range(len(y_true)):\n",
        "        P_i = get_path(G, y_pred[i]) \n",
        "        T_i = get_path(G, y_true[i])\n",
        "        P_T += len(P_i.intersection(T_i))\n",
        "        P += len(P_i)\n",
        "        T += len(T_i)\n",
        "    hP = P_T / P\n",
        "    hR = P_T / T\n",
        "    hF = 2 * hP * hR / (hP + hR)\n",
        "    return hF\n",
        "\n",
        "def train_epoch(model, loss_function, optimizer, train_loader, val_loader,\n",
        "                num_epoch=3, scheduler=None, device='cuda', \n",
        "                needed_features=['input_ids', 'token_type_ids', 'attention_mask']):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_batches = 0\n",
        "    step = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        label = batch[\"label\"].to(device)\n",
        "\n",
        "        seed_everything(42)\n",
        "        model_out = model(*[batch[fname].to(device) for fname in needed_features])\n",
        "\n",
        "        batch_loss = loss_function(model_out, label)\n",
        "        batch_loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            model.parameters(), 1.0\n",
        "        )\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        running_loss += batch_loss.detach().cpu().numpy()\n",
        "        num_batches += 1\n",
        "    epoch_loss = running_loss / num_batches\n",
        "    print(\"train loss: \", epoch_loss)\n",
        "\n",
        "\n",
        "def val_epoch(model, loss_function, val_loader, device='cpu', target_names = None,\n",
        "              needed_features=['input_ids', 'token_type_ids', 'attention_mask']):\n",
        "    # target_names - список наименований категорий в one-hot представлении целевой переменной. Формат элементов - str.\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_batches = 0\n",
        "    model_prob = None\n",
        "    true_label = None\n",
        "\n",
        "    for batch in val_loader:\n",
        "        label = batch[\"label\"].to(device)\n",
        "        true_class = batch[\"true_class\"]\n",
        "        model_out = model(*[batch[fname].to(device) for fname in needed_features])\n",
        "        \n",
        "        batch_prob = torch.softmax(model_out, dim=1).detach().cpu().numpy()\n",
        "        batch_loss = loss_function(model_out, label)\n",
        "\n",
        "        if model_prob is None:\n",
        "            model_prob = batch_prob\n",
        "            true_label = label.detach().cpu().numpy()\n",
        "            true_class_model = true_class.detach().cpu().numpy()\n",
        "        else:\n",
        "            model_prob = np.vstack((model_prob, batch_prob))\n",
        "            true_label = np.vstack((true_label, label.detach().cpu().numpy()))\n",
        "            true_class_model = np.hstack((true_class_model, true_class.detach().cpu().numpy()))\n",
        "\n",
        "        running_loss += batch_loss.detach().cpu().numpy()\n",
        "        num_batches += 1\n",
        "        \n",
        "    epoch_loss = running_loss/num_batches\n",
        "    print(\"val loss: \", epoch_loss)\n",
        "\n",
        "    pred_idx = np.argmax(model_prob, axis=1)\n",
        "    pred_label = np.array([int(target_names[i]) for i in pred_idx])  \n",
        "    epoch_f1 = f1_score(true_class_model, pred_label, average='micro')\n",
        "    \n",
        "    return epoch_f1\n",
        "    \n",
        "\n",
        "def infer(model, val_loader, device='cpu',\n",
        "          needed_features=['input_ids', 'token_type_ids', 'attention_mask']):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_batches = 0\n",
        "    model_prob = None\n",
        "    true_label = None\n",
        "    for batch in tqdm(val_loader):\n",
        "        model_out = model(*[batch[fname].to(device) for fname in needed_features])\n",
        "        batch_prob = torch.softmax(model_out, dim=1).detach().cpu().numpy()\n",
        "        \n",
        "        if model_prob is None:\n",
        "            model_prob = batch_prob\n",
        "        else:\n",
        "            model_prob = np.vstack((model_prob, batch_prob))\n",
        "\n",
        "    return model_prob\n",
        "\n",
        "\n",
        "def infer_single(model, val_loader, device='cpu',\n",
        "                 needed_features=['input_ids', 'token_type_ids', 'attention_mask']):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_batches = 0\n",
        "    model_prob = None\n",
        "    true_label = None\n",
        "    for batch in tqdm(val_loader):\n",
        "        model_out = model(*[batch[fname].to(device) for fname in needed_features])[\"logits\"]\n",
        "        batch_prob = torch.softmax(model_out, dim=1).detach().cpu().numpy()\n",
        "        \n",
        "        if model_prob is None:\n",
        "            model_prob = batch_prob\n",
        "        else:\n",
        "            model_prob = np.vstack((model_prob, batch_prob))\n",
        "\n",
        "    return model_prob\n",
        "\n",
        "\n",
        "def train_model(model, loss_function, optimizer, train_loader, val_loader, target_names = None,\n",
        "                num_epoch=3, scheduler=None, device='cpu', name_to_save='model.pt',\n",
        "                best_val_score=0.0, needed_features=['input_ids', 'token_type_ids', 'attention_mask']):\n",
        "    # target_names - список наименований категорий в one-hot представлении целевой переменной. Формат элементов - str.\n",
        "    for epoch in range(num_epoch):\n",
        "        train_epoch(model, loss_function, optimizer, train_loader, val_loader, \n",
        "                    num_epoch, scheduler, device, needed_features)\n",
        "        \n",
        "        val_score = val_epoch(model, loss_function, val_loader, device, target_names,\n",
        "                    needed_features)\n",
        "        print(f\"val f1_score after {epoch+1} epoch: {val_score}\")\n",
        "\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            print(\"new best score! Saving model...\")\n",
        "            torch.save(model, name_to_save)\n",
        "        print(\"*\"*100)"
      ],
      "metadata": {
        "id": "18vxjV4nydW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Code"
      ],
      "metadata": {
        "id": "pDnWLnnnydoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ROosY0qEyh8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SvG4fIRUyiA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost"
      ],
      "metadata": {
        "id": "x9S-nnhc7Ll5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "guqrV-yvgfeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_features = [0, 1, 2]\n",
        "train_dataset = Pool(data=x_train,\n",
        "                     label=y_train,            \n",
        "                     text_features=text_features)\n",
        "\n",
        "eval_dataset = Pool(data=x_test,\n",
        "                    label=y_test,\n",
        "                    text_features=text_features)"
      ],
      "metadata": {
        "id": "RNjm6T0mgg4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize CatBoostClassifier\n",
        "model_1000 = CatBoostClassifier(iterations=50,\n",
        "                           learning_rate=0.1,\n",
        "                           depth=2,\n",
        "                           loss_function='MultiClass',\n",
        "                           task_type=\"GPU\",\n",
        "                           custom_loss=[\"Accuracy\"],\n",
        "                           save_snapshot=True,\n",
        "                           snapshot_file=\"snapshot_1000.bkp\",\n",
        "                           snapshot_interval=1,\n",
        "                           random_seed=43               \n",
        "                           \n",
        "                           )  "
      ],
      "metadata": {
        "id": "GfJVG7NF5ouO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "\n",
        "history = model_1000.fit(train_dataset,\n",
        "                         eval_set=eval_dataset,\n",
        "          logging_level='Verbose',\n",
        "          plot=False\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c973531dd36e477fb4b5596c9ff5f628"
          ]
        },
        "id": "uiyCvttJ-FqJ",
        "outputId": "71bc90f6-360b-4d50-ded0-aa0544f2d77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c973531dd36e477fb4b5596c9ff5f628"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1000.save_model(fname='/content/drive/My Drive/Colab Notebooks/Data/Flat_model_100',\n",
        "                 format=\"cbm\",)"
      ],
      "metadata": {
        "id": "9kwUrYyyzJ_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ],
      "metadata": {
        "id": "TM-5M0gXfu9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(iterations=50,\n",
        "                           learning_rate=0.1,\n",
        "                           depth=2,\n",
        "                           loss_function='MultiClass',\n",
        "                          #  task_type=\"GPU\",\n",
        "                           custom_loss=[\"Accuracy\"],\n",
        "                           save_snapshot=True,\n",
        "                           snapshot_file=\"snapshot.bkp\",\n",
        "                           snapshot_interval=1,\n",
        "                           random_seed=43                   \n",
        "                           \n",
        "                           )  \n",
        "\n",
        "model.load_model('/content/drive/My Drive/Colab Notebooks/Data/Flat_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJkz_PxEfs7o",
        "outputId": "60627cf8-bf62-4cd6-9c86-1a5317b020aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f179c5affd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_class = model.predict(eval_dataset)"
      ],
      "metadata": {
        "id": "j2BivCl7bHLw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "5c786ada-47ac-4023-d06f-510ee1a09373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9d877236b860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Simple model validation accuracy: {accuracy_score(y_test, preds_class)}')"
      ],
      "metadata": {
        "id": "rmmetyR8zBJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "1f74eb3a-a10b-4193-9a21-60a7459fafde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d90ce5b5bea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Simple model validation accuracy: {accuracy_score(y_test, preds_class)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1 Score"
      ],
      "metadata": {
        "id": "dLIt32o_byWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
        "\n",
        "model = CatBoostClassifier(iterations=50,\n",
        "                           learning_rate=0.1,\n",
        "                           depth=2,\n",
        "                           loss_function='MultiClass',\n",
        "                          #  task_type=\"GPU\",\n",
        "                           custom_loss=[\"Accuracy\"],\n",
        "                           save_snapshot=True,\n",
        "                           snapshot_file=\"snapshot.bkp\",\n",
        "                           snapshot_interval=1,\n",
        "                           random_seed=43                   \n",
        "                           \n",
        "                           )  \n",
        "model.load_model('/content/drive/My Drive/Colab Notebooks/Data/Flat_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br_iXffecALr",
        "outputId": "359815c0-e348-4b8e-ac09-98fecef74e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f179c53e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_class = model.predict(eval_dataset)"
      ],
      "metadata": {
        "id": "r7U2jbzhcAcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 calculate\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_test, preds_class, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8loe426ewGT",
        "outputId": "73b49fd5-37e7-49b1-dec6-48cfa6d41e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3417219401932432"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}